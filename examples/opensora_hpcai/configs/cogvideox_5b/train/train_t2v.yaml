# model
model_version: CogVideoX-5B
pretrained_model_path:
  - "models/CogVideoX-5b/transformer/diffusion_pytorch_model-00001-of-00002.safetensors"
  - "models/CogVideoX-5b/transformer/diffusion_pytorch_model-00002-of-00002.safetensors"
model_max_length: 226

noise_scheduler: ddpm
noise_schedule: quad
v_pred: True
beta_start: 0.00085
beta_end: 0.012
snr_shift_scale: 1.0
rescale_betas_zero_snr: True

vae_type: "CogVideoX-VAE"
vae_checkpoint: "models/CogVideoX-5b/vae/diffusion_pytorch_model.safetensors"
vae_dtype: fp16
sd_scale_factor: 0.7

enable_flash_attention: True
use_recompute: True

# data
image_size: [ 480, 720 ]
num_frames: 49
num_parallel_workers: 2
prefetch_size: 4
max_rowsize: -1
text_drop_prob: 0.1

# precision
dtype: bf16
loss_scaler_type: static
init_loss_scale: 1
native_precision: True

# mindspore params, refer to https://www.mindspore.cn/docs/zh-CN/r2.4.0/api_python/mindspore/mindspore.set_context.html
mode: 1
jit_level: "O0"

# training hyper-params
scheduler: "constant"
start_learning_rate: 2.e-5
end_learning_rate: 2.e-5
warmup_steps: 1000

batch_size: 1
clip_grad: True
max_grad_norm: 1.0
use_ema: False

optim: "adamw_re"
optim_eps: 1.e-8
weight_decay: 1.e-4
betas: [0.9, 0.95]

epochs: 10000
ckpt_save_interval: 20
ckpt_max_keep: 3

mask_ratios:
  identity: 1.0
